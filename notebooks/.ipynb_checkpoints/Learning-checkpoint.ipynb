{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff4b0b8-2ef3-4923-aae4-ad138164b241",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8888458a-1c86-4a0d-91af-1958b0c376bb",
   "metadata": {},
   "source": [
    "FOLDER_PATH = '/Users/artemzmailov/Desktop/GiveMeSomeCredit/'\n",
    "dataset_train = pd.read_csv(FOLDER_PATH + 'data/train_full_scaled_pipeline_v1.csv', index_col = 0)\n",
    "dataset_test = pd.read_csv(FOLDER_PATH + 'data/Kaggle_test_full_scaled_pipeline_v1.csv', index_col = 0)\n",
    "train_label = pd.read_csv(FOLDER_PATH + 'data/train_label_pipeline_v1.csv', index_col = 0).squeeze()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d066dfe8-58b6-48f5-b19b-0c936a4005cd",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ed0684-4d39-4e10-b765-1ea0b3ef1809",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components = 10)\n",
    "# pca_train = pca.fit(dataset_train)\n",
    "# fig = px.bar(np.sort(pca_train.explained_variance_ratio_)[::-1])\n",
    "# fig.show()\n",
    "\n",
    "# for i in range(8, 1, -1):\n",
    "#     print(i)\n",
    "#     pca = PCA(n_components = i)\n",
    "#     pca_train = pca.fit(dataset_train)\n",
    "#     cumsum = np.cumsum(np.sort(pca_train.explained_variance_ratio_)[::-1])\n",
    "#     fig = px.bar(cumsum)\n",
    "#     fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9b1968d8-401e-42dd-9e83-5f5fb7047e72",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219c4c2b-b44e-4c68-a813-b094b658da67",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "#     dataset_train,\n",
    "#     train_label,\n",
    "#     stratify = train_label,\n",
    "#     random_state = 42,\n",
    "#     shuffle = True,\n",
    "#     test_size = 0.2)\n",
    "\n",
    "\n",
    "repeated_kfold = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2, random_state = 42)\n",
    "kfold = StratifiedKFold(n_splits = 5,shuffle = True, random_state = 42)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd3d5dfa-24ba-40d2-9ac9-a59e1f854ecc",
   "metadata": {},
   "source": [
    "# print(Y_train.sum() / X_train.shape[0], Y_test.sum() / X_test.shape[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84497002-ff8d-415d-88a4-53c68215b354",
   "metadata": {},
   "source": [
    "weights_scale = train_label.value_counts().iloc[0] / train_label.value_counts().iloc[1]\n",
    "weights_scale"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb355d58-6903-412e-b001-cc2997971e4e",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e109ef-0fd6-40e6-ba5e-2bd9ede4bd0e",
   "metadata": {},
   "source": [
    "## BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b5f49d-b087-49b1-903e-7f6c214e4546",
   "metadata": {},
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "repeated_kfold = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2, random_state = 42)\n",
    "kfold = StratifiedKFold(n_splits = 5,shuffle = True, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_reg = LogisticRegressionCV(cv = repeated_kfold,\n",
    "                                class_weight = 'balanced',\n",
    "                                random_state = 42,\n",
    "                                scoring = 'roc_auc',\n",
    "                                n_jobs = -1).fit(dataset_train, train_label)\n",
    "\n",
    "print(f\"Лучший C: {log_reg.C_}\")\n",
    "print(f\"CV scores для каждого C: {log_reg.scores_}\")\n",
    "print(f\"Средний AUC на CV: {log_reg.scores_[1].mean():.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c291c1bb-ddd3-4d2c-add2-4992f25be7ab",
   "metadata": {},
   "source": [
    "list(log_reg.scores_.values())[0].mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158c0acb-367d-4c88-9db6-fdf4c8d1ff39",
   "metadata": {},
   "source": [
    "import joblib\n",
    "joblib.dump(log_reg, FOLDER_PATH + 'models/log_reg.pkl')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "973a13ba-21e4-4dc9-92e3-390a59935f59",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import numpy as np\n",
    "\n",
    "log_reg = LogisticRegressionCV(\n",
    "    cv=5,                          # 5-фолдовая кросс-валидация\n",
    "    class_weight='balanced',       # балансировка классов\n",
    "    random_state=42,              \n",
    "    scoring='roc_auc',            # метрика AUC\n",
    "    n_jobs=-1,                   # используем все ядра CPU\n",
    "    Cs=np.logspace(-3, 3, 20),   # 20 значений C от 0.001 до 1000\n",
    "    penalty='l2',                # L2 регуляризация\n",
    "    solver='lbfgs',             # быстрый solver для L2\n",
    "    max_iter=2000,             # достаточно для сходимости\n",
    "    tol=1e-4,                 # точность\n",
    "    verbose=1                 # показываем прогресс\n",
    ").fit(dataset_train, train_label)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ С CV\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Лучший C: {log_reg.C_[0]:.4f}\")\n",
    "print(f\"Средний AUC на CV: {log_reg.scores_[1].mean():.4f}\")\n",
    "print(f\"Стандартное отклонение: {log_reg.scores_[1].mean(axis=0).std():.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9d5ae4-51e1-4eea-bf23-eaa02e0578bd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import numpy as np\n",
    "\n",
    "# Расширенная сетка вокруг оптимального C = 483.29\n",
    "log_reg_final = LogisticRegressionCV(\n",
    "    cv=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    Cs=[100, 200, 300, 400, 450, 475, 483, 490, 500, 550, 600, 700, 800, 900, 1000],  # целенаправленный поиск\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=3000,\n",
    "    tol=1e-4,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ").fit(dataset_train, train_label)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ФИНАЛЬНАЯ ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (L1) - УТОЧНЕНИЕ C\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Лучший C: {log_reg_final.C_[0]:.4f}\")\n",
    "print(f\"Средний AUC на CV: {log_reg_final.scores_[1].mean():.4f}\")\n",
    "print(f\"Стандартное отклонение: {log_reg_final.scores_[1].mean(axis=0).std():.4f}\")\n",
    "print(f\"Отобрано признаков: {np.sum(log_reg_final.coef_[0] != 0)}/{len(log_reg_final.coef_[0])}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ba1819-e095-4b5b-baf7-2203f238804d",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_final = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    C = 550, \n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    max_iter=3000,\n",
    "    tol=1e-4,\n",
    ").fit(dataset_train, train_label)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(log_reg_final, FOLDER_PATH + 'models/log_reg_best.pkl')\n",
    "\n",
    "\n",
    "result = pd.DataFrame({'Id': dataset_test.index, 'Probability': log_reg_final.predict_proba(dataset_test)[:,1]})\n",
    "result.to_csv(FOLDER_PATH +'data/result_log_reg_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96dced70-2826-42da-93c1-c7f2780eec99",
   "metadata": {},
   "source": [
    "result = pd.DataFrame({'Id': dataset_test.index, 'Probability': log_reg.predict_proba(dataset_test)[:,1]})\n",
    "result.to_csv(FOLDER_PATH +'data/result_baseline_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03876fe8-5653-41d6-8dbe-580ddca856ea",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5b975f-ce9d-4c64-848f-58007a817d15",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ed67be4-16ab-4a92-9416-cebd255c1aa6",
   "metadata": {},
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = SVC(random_state = 42, class_weight = 'balanced')\n",
    "params = {'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "grid_search_cv = GridSearchCV(estimator = svc,\n",
    "                              param_grid = params,\n",
    "                              cv = kfold,\n",
    "                              scoring = 'roc_auc',\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 2).fit(X_train, Y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c5ab794-1d2f-4bd8-8d82-5883b97758c7",
   "metadata": {},
   "source": [
    "svc = SVC(random_state = 42,\n",
    "          class_weight = 'balanced',\n",
    "          verbose = 2,\n",
    "          C = 1,\n",
    "          kernel = 'rbf',\n",
    "          degree = 3).fit(X_train, Y_train)\n",
    "CV_score = cross_val_score(svc,\n",
    "                    X = X_test,\n",
    "                    y = Y_test,\n",
    "                    cv = kfold,\n",
    "                    scoring = 'roc_auc',\n",
    "                    n_jobs = -1)\n",
    "CV_score.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "936b807c-3549-4740-b204-99d2aafeb067",
   "metadata": {},
   "source": [
    "pd.DataFrame(grid_search_cv.cv_results_) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39afc624-3801-4e4a-845f-e55ba83ef05f",
   "metadata": {},
   "source": [
    "grid_search_cv.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8ce51f-172f-45f2-b69b-e0a55749e8ea",
   "metadata": {},
   "source": [
    "## Линейный SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c1e58d4-fb77-4935-a2bd-9e5a6f654f58",
   "metadata": {},
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "linear_svc = LinearSVC(random_state = 42, class_weight = 'balanced', max_iter = 10000, penalty = 'l2', loss = 'squared_hinge')\n",
    "params = {'tol':[1e-4,1e-3,1e-2,1e-1],\n",
    "         'C':[0.01,0.1,1,10,100]}\n",
    "linear_search_cv = GridSearchCV(estimator = linear_svc,\n",
    "                              param_grid = params,\n",
    "                              cv = kfold,\n",
    "                              scoring = 'roc_auc',\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 2).fit(X_train, Y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "270fd0b8-d649-4f47-8891-614a92fa9f44",
   "metadata": {},
   "source": [
    "linear_search_cv.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d7f0318-632f-4f59-88ce-374e7173298f",
   "metadata": {},
   "source": [
    "best_linear_svc = linear_search_cv.best_estimator_\n",
    "result_linear_svc = pd.DataFrame({'Id': dataset_test.index + 1, 'Probability': best_linear_svc.predict(dataset_test)})\n",
    "result_linear_svc.to_csv(FOLDER_PATH +'data/result_linear_svc.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e713e7e-28f5-4cdf-973b-88b2b0b1402a",
   "metadata": {},
   "source": [
    "linear_search_cv_2.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b1125503-ed06-417f-880f-a46219d8bf7a",
   "metadata": {},
   "source": [
    "## SVC RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67dc4236-0b5a-4031-9c72-873f7a6779db",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "svc_rbf = SVC(random_state = 42, class_weight = 'balanced', kernel = 'rbf', C = 10).fit(X_train, Y_train)\n",
    "y_score = svc_rbf.decision_function(X_test)\n",
    "roc_auc_rbf = roc_auc_score(Y_test, y_score)\n",
    "roc_auc_rbf"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c8561e-dc5e-45a5-a583-cd47516418ca",
   "metadata": {},
   "source": [
    "result_rbf = pd.DataFrame({'Id': dataset_test.index + 1, 'Probability': svc_rbf.predict(dataset_test)})\n",
    "result_rbf.to_csv(FOLDER_PATH +'data/result_rbf.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "310497c4-6b11-42ab-acd0-5f5c3648e2a4",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afc6f771-4e0b-4411-9e6b-564e58c22cc5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dtc = DecisionTreeClassifier(class_weight = 'balanced', random_state = 42)\n",
    "dtc_params = {\n",
    "    'max_depth': [3, 5, 7,8, 10,15, None],    \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4,6,8,10],              \n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_impurity_decrease': [0.0, 0.001, 0.005, 0.01]}\n",
    "dtc_search_cv = GridSearchCV(estimator = dtc,\n",
    "                              param_grid = dtc_params,\n",
    "                              cv = kfold,\n",
    "                              scoring = 'roc_auc',\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 2).fit(dataset_train, train_label)\n",
    "          "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8053cb98-b7d3-4cf7-b4ce-e85add4dcf8a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dtc_score = pd.DataFrame(dtc_search_cv.cv_results_)\n",
    "dtc_best_params = dtc_score[dtc_score['mean_test_score'].sort_values(ascending = False) > 0.85]['params']\n",
    "for row in dtc_best_params.items():\n",
    "    print(row)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ee1d54-46cd-4737-abb2-935a3496551f",
   "metadata": {},
   "source": [
    "dtc_search_cv.best_score_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1067048e-a291-4892-a6d3-50f354be2518",
   "metadata": {},
   "source": [
    "dtc_search_cv.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e256cecb-ac79-4936-9750-6eaede7e02c4",
   "metadata": {},
   "source": [
    "#dtc_score.iloc[dtc_score['mean_test_score'].sort_values(ascending = False).index].head(50)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "774054f9-b6fd-40f8-afc6-589c8106f168",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "best_dtc = dtc_search_cv.best_estimator_\n",
    "dtc_y_proba = best_dtc.predict_proba(dataset_train)[:,1]\n",
    "dtc_roc_auc = roc_auc_score(train_label, dtc_y_proba)\n",
    "dtc_roc_auc"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "582f77d0-b1a1-48fe-a72f-2d9419c94d63",
   "metadata": {},
   "source": [
    "result_dtc = pd.DataFrame({'Id': dataset_test.index, 'Probability': best_dtc.predict_proba(dataset_test)[:,1]})\n",
    "result_dtc.to_csv(FOLDER_PATH +'data/result_dtc_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "514ad8b0-76d7-48a1-9f31-c7b93d3c78d1",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17121682-1f3b-4920-99de-4ffd14708afd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 100, n_jobs = -1, random_state = 42, class_weight = 'balanced', criterion = 'gini')\n",
    "rfc_params = {               \n",
    "    'max_depth': [8, 10, 15, None],           \n",
    "    'min_samples_split': [2, 10],            \n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss']}     \n",
    "kfold_rfc = StratifiedKFold(n_splits = 3,shuffle = True, random_state = 42)\n",
    "rfc_search_cv = GridSearchCV(estimator = rfc,\n",
    "                              param_grid = rfc_params,\n",
    "                              cv = kfold_rfc,\n",
    "                              scoring = 'roc_auc',\n",
    "                              n_jobs = -1,\n",
    "                              verbose = 2).fit(dataset_train, train_label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deaeecfe-1728-49c5-934c-f8019ba0f245",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pd.DataFrame(rfc_search_cv.cv_results_)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d394939d-a14b-46fb-a83c-0636b960ad73",
   "metadata": {},
   "source": [
    "rfc_search_cv.best_score_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5940143e-0b07-48d5-8ec9-540e66c1e401",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "rfc_score = pd.DataFrame(rfc_search_cv.cv_results_)\n",
    "rfc_best_params = rfc_score[rfc_score['mean_test_score'].sort_values(ascending = False) > 0.855][['params', 'mean_test_score', 'rank_test_score']]\n",
    "for row in rfc_best_params.iterrows():\n",
    "    for idx, val in row[1].items():\n",
    "        print(f'{idx}: {val}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d7759be4-ad7f-432e-b9fb-656d48c21d5d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "rfc_score['mean_test_score'].sort_values(ascending = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "790d75c8-0f9b-4335-aeb8-15efd293cd13",
   "metadata": {},
   "source": [
    "rfc_search_cv.best_score_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "09a8db84-b60d-48b7-9803-93c0892c51ae",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Топ 5 вариант: mean_test_score: 0.8597021546202702\n",
    "rfc_best_estimator = RandomForestClassifier(n_estimators = 200,\n",
    "                                  n_jobs = -1,\n",
    "                                  random_state = 42,\n",
    "                                  class_weight = 'balanced',\n",
    "                                  criterion = 'gini',\n",
    "                                  max_depth = 8,\n",
    "                                  min_samples_leaf = 4,\n",
    "                                  min_samples_split = 10)\n",
    "\n",
    "rfc_cv_score = cross_val_score(estimator = rfc_best_estimator,\n",
    "                               X = X_train,\n",
    "                               y = Y_train,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = kfold_rfc,\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f05ada2c-994d-4895-8daa-0bcd75fce4ba",
   "metadata": {},
   "source": [
    "rfc_cv_score.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd9a42cb-fa8f-433c-98cd-2b2e4322b94b",
   "metadata": {},
   "source": [
    "rfc_best = rfc_best_estimator.fit(dataset_train, train_label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4014ae8c-18d1-4cef-a5c2-b273828116ae",
   "metadata": {},
   "source": [
    "rfc_test_score = rfc_search_cv.best_estimator_.predict_proba(dataset_train)[:,1]\n",
    "rfc_roc_auc = roc_auc_score(train_label, rfc_test_score)\n",
    "rfc_roc_auc"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a59c9a2-c12f-43fe-a788-50698a902ce2",
   "metadata": {},
   "source": [
    "rfc_best = rfc_search_cv.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "182d6e64-37b3-4108-959f-7ed4dffcc5b7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "result_rfc = pd.DataFrame({'Id': dataset_test.index, 'Probability': rfc_search_cv.best_estimator_.predict_proba(dataset_test)[:,1]})\n",
    "result_rfc.to_csv(FOLDER_PATH +'data/result_rfc_pipeline_v1.csv', index = False)\n",
    "result_rfc"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6d65eec8-646e-4a54-939f-10d62f774c52",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38953cf2-f75a-4c9b-8ff5-3553ade758aa",
   "metadata": {},
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "xgb = XGBClassifier(verbosity = 2,\n",
    "                    n_estimators = 100,\n",
    "                    learning_rate = 0.3,\n",
    "                    min_split_loss = 0,\n",
    "                    max_depth = 6,\n",
    "                    min_child_weight = 1,\n",
    "                    reg_lambda = 1,\n",
    "                    reg_alpha = 0,\n",
    "                    scale_pos_weight = 1,\n",
    "                        random_state = 42).fit(dataset_train,train_label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fc07e3d-0953-4042-9c23-147cdb7d7d05",
   "metadata": {},
   "source": [
    "xgb_baseline = XGBClassifier(random_state = 42).fit(dataset_train,train_label)\n",
    "xgb_test_score = xgb_baseline.predict_proba(dataset_train)[:,1]\n",
    "xgb_roc_auc = roc_auc_score(train_label, xgb_test_score)\n",
    "xgb_roc_auc"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53a26264-edfe-4ce8-9367-d89823a7dee8",
   "metadata": {},
   "source": [
    "result_xgb_baseline = pd.DataFrame({'Id': dataset_test.index, 'Probability': xgb_baseline.predict_proba(dataset_test)[:,1]})\n",
    "result_xgb_baseline.to_csv(FOLDER_PATH +'data/result_xgb_baseline_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "278dcaf0-a480-4488-b042-3a3a283465db",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "weights_scale = train_label.value_counts().iloc[0] / train_label.value_counts().iloc[1]\n",
    "\n",
    "xgb = XGBClassifier(random_state = 42, scale_pos_weight = weights_scale, n_estimators = 100)\n",
    "kfold_xgb = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.001, 0.01, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 1.5, 2],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'min_split_loss': [0, 0.001,0.01,0.1]\n",
    "}\n",
    "rand_search_cv = RandomizedSearchCV(estimator = xgb,\n",
    "                                   param_distributions = xgb_params,\n",
    "                                   n_iter = 300,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   n_jobs = -1,\n",
    "                                   cv = kfold_xgb,\n",
    "                                   verbose = 2).fit(dataset_train,train_label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91a5eb55-607c-4d42-a154-7691daefe571",
   "metadata": {},
   "source": [
    "xgb_search_res = pd.DataFrame(rand_search_cv.cv_results_).loc[:,['params','mean_test_score', 'rank_test_score']].sort_values(by = ['rank_test_score'])\n",
    "for idx,row in xgb_search_res.iterrows():\n",
    "    print(row[1],row[2])\n",
    "    for i,val in row[0].items():\n",
    "        print(f'{i}: {val}')\n",
    "    print('-'*30)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3911c1a1-57ce-4b7e-864a-0f4f1a9f6905",
   "metadata": {},
   "source": [
    "xgb_search_res"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "809206e1-edf7-468e-945f-d9b9970c61c9",
   "metadata": {},
   "source": [
    "rand_search_cv.best_score_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24581fab-2da4-4f8c-a2dc-b1f955bf3fac",
   "metadata": {},
   "source": [
    "rand_search_cv.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60cb1a68-34aa-4d23-ab27-25d1dcba824e",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "# xgb_best_estimator = XGBClassifier(n_estimators = 100,\n",
    "#                         random_state = 42,\n",
    "#                         scale_pos_weight = weights_scale,\n",
    "#                         colsample_bytree = 0.7,\n",
    "#                         learning_rate = 0.1,\n",
    "#                         max_depth = 4,\n",
    "#                         min_child_weight = 5,\n",
    "#                         reg_alpha = 1,\n",
    "#                         reg_lambda = 1,\n",
    "#                         subsample = 0.9,\n",
    "#                         min_split_loss = 0.001)\n",
    "\n",
    "xgb_best_estimator = rand_search_cv.best_estimator_\n",
    "\n",
    "xgb_cv_score = cross_val_score(estimator = xgb_best_estimator,\n",
    "                               X = dataset_train,\n",
    "                               y = train_label,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = kfold_xgb,\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dead49f0-ebb9-4920-bfe2-f8ac4287a2c7",
   "metadata": {},
   "source": [
    "xgb_cv_score.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae9fedc9-0cf5-43cc-aa87-5e3b10db70d7",
   "metadata": {},
   "source": [
    "xgb_best = xgb_best_estimator.fit(dataset_train, train_label)\n",
    "xgb_best_test_score = xgb_best.predict_proba(dataset_train)[:,1]\n",
    "xgb_best_roc_auc = roc_auc_score(train_label, xgb_best_test_score)\n",
    "xgb_best_roc_auc"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13d4f8c5-eea7-418a-aaea-71336a501330",
   "metadata": {},
   "source": [
    "result_xgb_best = pd.DataFrame({'Id': dataset_test.index, 'Probability': xgb_best.predict_proba(dataset_test)[:,1]})\n",
    "result_xgb_best.to_csv(FOLDER_PATH +'data/result_xgb_best_local_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf72948-cd62-43a5-9af9-6b5c7021ffb0",
   "metadata": {},
   "source": [
    "## New EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1adaaf02-1e5e-4013-bae4-e00a9e579ea7",
   "metadata": {},
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_new_eda_best_model = XGBClassifier(n_estimators = 100,\n",
    "                                        random_state = 42,\n",
    "                                        scale_pos_weight = weights_scale,\n",
    "                                        colsample_bytree = 0.7,\n",
    "                                        learning_rate = 0.1,\n",
    "                                        max_depth = 4,\n",
    "                                        min_child_weight = 5,\n",
    "                                        reg_alpha = 1,\n",
    "                                        reg_lambda = 1,\n",
    "                                        subsample = 0.9).fit(X_train, Y_train)\n",
    "\n",
    "xgb_test_score = xgb_new_eda_best_model.predict_proba(X_test)[:,1]\n",
    "xgb_roc_auc = roc_auc_score(Y_test, xgb_test_score)\n",
    "print(xgb_roc_auc)\n",
    "res_xgb_new_eda_best_model = pd.DataFrame({'Id': dataset_test.index + 1, 'Probability': xgb_new_eda_best_model.predict(dataset_test)})\n",
    "res_xgb_new_eda_best_model.to_csv(FOLDER_PATH +'data/res_new_eda_xgb.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1c085e70-1977-47f8-b8a0-416cc716d4c7",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3df3e5df-527d-4c1b-bf33-483284ba2981",
   "metadata": {},
   "source": [
    "#LGBM Baseline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lgbm_baseline_estimator = LGBMClassifier(random_state = 42, scale_pos_weight = weights_scale)\n",
    "kfold_lgbm = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\n",
    "lgbm_cv_score = cross_val_score(estimator = lgbm_baseline_estimator,\n",
    "                               X = X_train,\n",
    "                               y = Y_train,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = kfold_lgbm,\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9758bb24-9f87-4fee-b1ca-52a510e5e355",
   "metadata": {},
   "source": [
    "lgbm_cv_score.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1084f833-85ae-4de8-9a1d-da3aa3bd9a33",
   "metadata": {},
   "source": [
    "LGBMClassifier(colsample_bytree=0.7162219560799004,\n",
    "               learning_rate=0.003721300336530525, max_depth=5,\n",
    "               n_estimators=2520, random_state=0, reg_lambda=7.017000573168227,\n",
    "               subsample=0.6716479399150603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceca89e6-4d25-49f4-a67a-218be1553369",
   "metadata": {},
   "source": [
    "lgbm_best = LGBMClassifier(random_state=42, scale_pos_weight = weights_scale).fit(X_train, Y_train)\n",
    "lgbm_best_test_score = lgbm_best.predict_proba(X_test)[:,1]\n",
    "lgbm_best_roc_auc = roc_auc_score(Y_test, lgbm_best_test_score)\n",
    "lgbm_best_roc_auc"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "545842cb-aac8-4fd3-b14d-920a58d967f7",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7963d0f-9ba6-4feb-9876-51d2d5eadf00",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "catbst_baseline_estimator = CatBoostClassifier(\n",
    "    auto_class_weights='Balanced',\n",
    "    random_seed=42,\n",
    "    verbose=True)\n",
    "kfold_catbst = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\n",
    "catbst_cv_score = cross_val_score(estimator = catbst_baseline_estimator,\n",
    "                               X = X_train,\n",
    "                               y = Y_train,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = kfold_catbst,\n",
    "                               n_jobs = -1,\n",
    "                               verbose = 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62d79ab-6167-4f39-b361-df0acc786d67",
   "metadata": {},
   "source": [
    "catbst_cv_score.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e78dd306-91c0-47ba-82bb-ab9eb774b0bf",
   "metadata": {},
   "source": [
    "## Kaggle XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56bb771c-235c-491d-8d9d-d58f70d818ae",
   "metadata": {},
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Читаем лучшие параметры\n",
    "with open(FOLDER_PATH +'kaggle_xgb/best_xgb_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "print(\"ЛУЧШИЕ ПАРАМЕТРЫ:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in best_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c88512c-a496-440c-9fcd-501c3bcf85bb",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "X_train = dataset_train.values.astype(np.float32)\n",
    "y_train = train_label.values\n",
    "final_params = best_params.copy()\n",
    "\n",
    "# Критически важные параметры для финальной модели\n",
    "final_params.update({\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 5000,  \n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbosity': 1,\n",
    "    'n_jobs': -1,  \n",
    "})\n",
    "\n",
    "print(\"\\nПАРАМЕТРЫ ФИНАЛЬНОЙ МОДЕЛИ:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in final_params.items():\n",
    "    print(f\"{key:25}: {value}\")\n",
    "\n",
    "# 4. Создаем и обучаем модель\n",
    "print(\"\\nОБУЧЕНИЕ ФИНАЛЬНОЙ МОДЕЛИ...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "final_model = XGBClassifier(**final_params)\n",
    "\n",
    "# Обучаем на всех данных\n",
    "final_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train)],\n",
    "    verbose=100  # Показывает прогресс каждые 100 деревьев\n",
    ")\n",
    "\n",
    "print(\"Финальная модель обучена!\")\n",
    "\n",
    "# 5. Сохраняем финальную модель\n",
    "# joblib.dump(final_model, 'final_xgb_model_gpu.pkl')\n",
    "# print(\"✓ Финальная модель сохранена в final_xgb_model_gpu.pkl\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69a19774-6c4a-4c81-85f8-8d425694c642",
   "metadata": {},
   "source": [
    "res_xgb_kaggle = pd.DataFrame({'Id': dataset_test.index, 'Probability': final_model.predict_proba(dataset_test)[:,1]})\n",
    "res_xgb_kaggle.to_csv(FOLDER_PATH +'data/xgb_kaggle_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd35dd7-3efa-469a-9ce6-411dacc87b14",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier, cv\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============================================================================\n",
    "# 1. ДИАГНОСТИКА: Смотрим кривую обучения\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ДИАГНОСТИКА ОПТИМАЛЬНОГО n_estimators\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Загружаем лучшие параметры с Kaggle\n",
    "with open(FOLDER_PATH +'kaggle_xgb/best_xgb_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# Подготовка данных\n",
    "if isinstance(dataset_train, pd.DataFrame):\n",
    "    X = dataset_train.values\n",
    "else:\n",
    "    X = dataset_train\n",
    "\n",
    "if isinstance(train_label, pd.Series):\n",
    "    y = train_label.values\n",
    "else:\n",
    "    y = train_label\n",
    "\n",
    "# Разделяем на train/validation (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Validation size: {X_val.shape}\")\n",
    "\n",
    "# Адаптируем параметры для CPU\n",
    "params = best_params.copy()\n",
    "if 'device' in params: del params['device']\n",
    "if params.get('tree_method') == 'gpu_hist': \n",
    "    params['tree_method'] = 'hist'\n",
    "    \n",
    "# Базовые параметры\n",
    "params.update({\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 0,\n",
    "})\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Тестируем разные n_estimators с early stopping\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ТЕСТИРУЕМ РАЗНОЕ КОЛИЧЕСТВО ДЕРЕВЬЕВ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_estimators_options = [100, 250, 500, 750, 1000, 1500, 2000, 3000]\n",
    "results = []\n",
    "\n",
    "for n_est in n_estimators_options:\n",
    "    model = XGBClassifier(**params, n_estimators=n_est, early_stopping_rounds=50)\n",
    "    \n",
    "    print(f\"\\nТестируем n_estimators = {n_est}...\")\n",
    "    \n",
    "    # Обучаем с валидацией\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Получаем историю ошибок\n",
    "    if hasattr(model, 'evals_result_'):\n",
    "        eval_results = model.evals_result_\n",
    "        val_auc = eval_results['validation_0']['auc'][-1]\n",
    "        best_iteration = model.best_iteration if hasattr(model, 'best_iteration') else n_est\n",
    "    else:\n",
    "        # Если нет истории, вычисляем вручную\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, y_pred)\n",
    "        best_iteration = n_est\n",
    "    \n",
    "    results.append({\n",
    "        'n_estimators': n_est,\n",
    "        'best_iteration': best_iteration,\n",
    "        'val_auc': val_auc,\n",
    "        'actual_used': min(best_iteration, n_est)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Best iteration: {best_iteration}\")\n",
    "    print(f\"  Validation AUC: {val_auc:.6f}\")\n",
    "\n",
    "# Создаем DataFrame с результатами\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"РЕЗУЛЬТАТЫ:\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Визуализируем результаты\n",
    "# ============================================================================\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results_df['n_estimators'], results_df['val_auc'], 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Validation AUC')\n",
    "plt.title('AUC vs n_estimators')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(results_df['n_estimators'], results_df['best_iteration'], 'ro-', linewidth=2, markersize=8)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Best iteration (early stopping)')\n",
    "plt.title('Early stopping point')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('n_estimators_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Находим оптимальное количество\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"АНАЛИЗ ОПТИМАЛЬНОГО КОЛИЧЕСТВА\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Находим лучший результат\n",
    "best_row = results_df.loc[results_df['val_auc'].idxmax()]\n",
    "print(f\"Лучший результат:\")\n",
    "print(f\"  n_estimators: {best_row['n_estimators']}\")\n",
    "print(f\"  Best iteration: {best_row['best_iteration']}\")\n",
    "print(f\"  Validation AUC: {best_row['val_auc']:.6f}\")\n",
    "\n",
    "# Проверяем, где AUC перестает расти\n",
    "auc_improvement = []\n",
    "for i in range(1, len(results_df)):\n",
    "    prev_auc = results_df.iloc[i-1]['val_auc']\n",
    "    curr_auc = results_df.iloc[i]['val_auc']\n",
    "    improvement = curr_auc - prev_auc\n",
    "    auc_improvement.append(improvement)\n",
    "    \n",
    "    if improvement < 0.0005:  # Если улучшение меньше 0.05%\n",
    "        optimal_n = results_df.iloc[i-1]['n_estimators']\n",
    "        print(f\"\\nОптимальная точка (улучшение < 0.05%):\")\n",
    "        print(f\"  n_estimators: {optimal_n}\")\n",
    "        print(f\"  AUC: {results_df.iloc[i-1]['val_auc']:.6f}\")\n",
    "        print(f\"  Следующее увеличение дает: {improvement:.6f}\")\n",
    "        break\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Кросс-валидация для точной оценки\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"КРОСС-ВАЛИДАЦИЯ С ЛУЧШИМИ ПАРАМЕТРАМИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Используем оптимальное количество деревьев\n",
    "optimal_n = int(best_row['best_iteration'] * 1.2)  # Берем с запасом 20%\n",
    "\n",
    "# Параметры для cv\n",
    "cv_params = params.copy()\n",
    "cv_params['n_estimators'] = optimal_n\n",
    "\n",
    "print(f\"Проводим кросс-валидацию с n_estimators = {optimal_n}...\")\n",
    "\n",
    "# Создаем DMatrix для xgboost cv\n",
    "import xgboost as xgb\n",
    "dmatrix = xgb.DMatrix(X, label=y)\n",
    "\n",
    "# Запускаем кросс-валидацию\n",
    "cv_results = xgb.cv(\n",
    "    cv_params,\n",
    "    dmatrix,\n",
    "    num_boost_round=optimal_n,\n",
    "    nfold=5,\n",
    "    stratified=True,\n",
    "    early_stopping_rounds=50,\n",
    "    seed=42,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "print(f\"Лучшее количество итераций по CV: {len(cv_results)}\")\n",
    "print(f\"Лучший AUC (train): {cv_results['train-auc-mean'].iloc[-1]:.6f}\")\n",
    "print(f\"Лучший AUC (test):  {cv_results['test-auc-mean'].iloc[-1]:.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. ФИНАЛЬНАЯ МОДЕЛЬ С ОПТИМАЛЬНЫМИ ПАРАМЕТРАМИ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ОБУЧЕНИЕ ФИНАЛЬНОЙ МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Определяем финальные параметры\n",
    "final_n_estimators = min(optimal_n, 2000)  # Ограничиваем 2000 для CPU\n",
    "\n",
    "print(f\"Используем n_estimators = {final_n_estimators}\")\n",
    "\n",
    "final_params = params.copy()\n",
    "final_params.update({\n",
    "    'n_estimators': final_n_estimators,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbosity': 1,\n",
    "})\n",
    "\n",
    "# Обучаем на всех данных\n",
    "print(\"Обучаем финальную модель на всех данных...\")\n",
    "final_model = XGBClassifier(**final_params)\n",
    "\n",
    "final_model.fit(\n",
    "    X, y,\n",
    "    eval_set=[(X, y)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061b157a-17b2-4894-8c33-b764bf43d066",
   "metadata": {},
   "source": [
    "xgb_model_best = final_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da346547-973f-4b10-9e43-bcd59b7ea9a1",
   "metadata": {},
   "source": [
    "import joblib\n",
    "joblib.dump(xgb_model_best,FOLDER_PATH + 'models/xgb_model_best.pkl')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64b7e88-b983-473c-968a-01ea455a1773",
   "metadata": {},
   "source": [
    "res_xgb_kaggle_best = pd.DataFrame({'Id': dataset_test.index, 'Probability': xgb_model_best.predict_proba(dataset_test)[:,1]})\n",
    "res_xgb_kaggle_best.to_csv(FOLDER_PATH +'data/xgb_kaggle_best_pipeline_v1.csv', index = False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57672f24-9e8c-4b3c-962c-3f1d66654cd2",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Получаем предсказания на трейне\n",
    "xgb_train_pred = final_model.predict_proba(X_train)[:, 1]\n",
    "rf_train_pred = rfc_best.predict_proba(X_train)[:, 1]  \n",
    "lr_train_pred = log_reg.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(\"Train AUC моделей:\")\n",
    "print(f\"XGB: {roc_auc_score(y_train, xgb_train_pred):.6f}\")\n",
    "print(f\"RF:  {roc_auc_score(y_train, rf_train_pred):.6f}\")\n",
    "print(f\"LR:  {roc_auc_score(y_train, lr_train_pred):.6f}\")\n",
    "\n",
    "# Подбор весов\n",
    "best_score = 0\n",
    "best_weights = None\n",
    "\n",
    "# Тестируем нормальные комбинации\n",
    "for xgb_w in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    for rf_w in [0.1, 0.2, 0.3, 0.4]:\n",
    "        lr_w = 1 - xgb_w - rf_w\n",
    "        if lr_w < 0: continue\n",
    "        \n",
    "        ensemble = xgb_w*xgb_train_pred + rf_w*rf_train_pred + lr_w*lr_train_pred\n",
    "        score = roc_auc_score(y_train, ensemble)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_weights = (xgb_w, rf_w, lr_w)\n",
    "\n",
    "print(f\"\\nЛучшие веса: XGB={best_weights[0]:.2f}, RF={best_weights[1]:.2f}, LR={best_weights[2]:.2f}\")\n",
    "print(f\"Train AUC: {best_score:.6f}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "762febe4-20ce-4349-bb51-140773589241",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Веса которые ты нашел\n",
    "xgb_weight = 0.7\n",
    "rf_weight = 0.3\n",
    "\n",
    "# Получаем предсказания от уже обученных моделей\n",
    "xgb_test_pred = final_model.predict_proba(dataset_test)[:, 1]\n",
    "rf_test_pred = rfc_best.predict_proba(dataset_test)[:, 1]\n",
    "\n",
    "# Ансамбль\n",
    "ensemble_pred = xgb_weight * xgb_test_pred + rf_weight * rf_test_pred\n",
    "\n",
    "# Создаем сабмит\n",
    "res_ensebmle_xgb_rf = pd.DataFrame({'Id': dataset_test.index, 'Probability': ensemble_pred})\n",
    "res_ensebmle_xgb_rf.to_csv(FOLDER_PATH +'data/res_ensebmle_xgb_rf_pipeline_v1.csv', index = False)\n",
    "\n",
    "print(\"Сабмит создан: ensemble_xgb07_rf03.csv\")\n",
    "print(f\"Веса: XGB={xgb_weight}, RF={rf_weight}\")\n",
    "print(f\"Min={ensemble_pred.min():.4f}, Max={ensemble_pred.max():.4f}, Mean={ensemble_pred.mean():.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4bf3d71-5ca1-4c9c-88ea-67f6abedb082",
   "metadata": {},
   "source": [
    "#1. LightGBM (часто лучше XGBoost)\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"Обучаем LightGBM...\")\n",
    "lgb_model.fit(dataset_train, train_label)\n",
    "\n",
    "# # 2. Создаем сабмит LightGBM\n",
    "# lgb_preds = lgb_model.predict_proba(dataset_test)[:, 1]\n",
    "# lgbm = pd.DataFrame({'Id': dataset_test.index, 'Probability': lgb_preds})\n",
    "# lgbm.to_csv(FOLDER_PATH +'data/res_lgbm_pipeline_v1.csv', index = False)\n",
    "\n",
    "# 3. Простое усреднение всех моделей\n",
    "print(\"\\nСоздаем усредненный сабмит всех моделей...\")\n",
    "\n",
    "# Получаем предсказания всех моделей\n",
    "xgb_preds = final_model.predict_proba(dataset_test)[:, 1]\n",
    "rf_preds = rfc_best.predict_proba(dataset_test)[:, 1]\n",
    "lr_preds = log_reg.predict_proba(dataset_test)[:, 1]\n",
    "lgb_preds = lgb_model.predict_proba(dataset_test)[:, 1]\n",
    "cat_preds = cat_model.predict_proba(dataset_test)[:, 1]\n",
    "# Простое усреднение\n",
    "avg_preds = (xgb_preds + rf_preds + lr_preds + lgb_preds + cat_preds) / 5\n",
    "\n",
    "# Взвешенное усреднение (подбираем вес для XGB)\n",
    "for xgb_weight in [#0.4, 0.5, 0.6, 0.7, \n",
    "                   0.75,0.8,0.9,0.95]:\n",
    "    other_weight = (1 - xgb_weight) / 4\n",
    "    weighted_preds = (\n",
    "        xgb_weight * xgb_preds +\n",
    "        other_weight * rf_preds +\n",
    "        other_weight * lr_preds +\n",
    "        other_weight * lgb_preds +\n",
    "        other_weight * cat_preds\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame({'Id': dataset_test.index,'Probability': weighted_preds}).to_csv(FOLDER_PATH +f'data/weighted_ensemble_cat_xgb{xgb_weight}.csv', index=False)\n",
    "    print(f\"Создал weighted_ensemble_cat_xgb{xgb_weight}.csv\")\n",
    "\n",
    "\n",
    "print(\"\\n✓ Все сабмиты созданы. Загружай на Kaggle и сравнивай!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "410c80c0-b218-4ba6-8068-fb5ef757087d",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Базовый LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1,\n",
    "    n_estimators=1000\n",
    ")\n",
    "\n",
    "# Сетка параметров для поиска\n",
    "lgb_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'num_leaves': [15, 31, 63, 127],\n",
    "    'max_depth': [-1, 5, 7, 9, 12],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1, 3],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1, 3],\n",
    "    'min_child_samples': [5, 10, 20, 30],\n",
    "}\n",
    "\n",
    "# Быстрый поиск\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "lgb_search = RandomizedSearchCV(\n",
    "    lgb_model, lgb_params,\n",
    "    n_iter=50,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Ищем параметры для LightGBM...\")\n",
    "lgb_search.fit(dataset_train, train_label)\n",
    "\n",
    "print(f\"Лучший LightGBM: {lgb_search.best_score_:.6f}\")\n",
    "\n",
    "# # Создаем сабмит\n",
    "# lgb_best = lgb_search.best_estimator_\n",
    "# lgb_preds = lgb_best.predict_proba(dataset_test)[:, 1]\n",
    "# pd.DataFrame({'Id': range(len(lgb_preds)), 'Probability': lgb_preds})\\\n",
    "#   .to_csv('lightgbm_tuned.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8325a7b7-8920-4701-932b-bcb755c308cd",
   "metadata": {},
   "source": [
    "lgb_search.best_estimator_\n",
    "'''\n",
    "Лучший LightGBM: 0.863677\n",
    "\n",
    "boosting_type \t'gbdt'\n",
    "num_leaves \t31\n",
    "max_depth \t5\n",
    "learning_rate \t0.01\n",
    "n_estimators \t1000\n",
    "subsample_for_bin \t200000\n",
    "objective \tNone\n",
    "class_weight \tNone\n",
    "min_split_gain \t0.0\n",
    "min_child_weight \t0.001\n",
    "min_child_samples \t10\n",
    "subsample \t0.8\n",
    "subsample_freq \t0\n",
    "colsample_bytree \t0.6\n",
    "reg_alpha \t3\n",
    "reg_lambda \t3\n",
    "random_state \t42\n",
    "n_jobs \t-1\n",
    "importance_type \t'split'\n",
    "verbose \t-1\n",
    "\n",
    "'''"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "154232e2-e56b-451d-8724-dc648bd87486",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Простой CatBoost\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=100,  # Показывает прогресс\n",
    "    task_type='CPU'  # Или 'GPU' если есть\n",
    ")\n",
    "\n",
    "cat_model.fit(dataset_train, train_label)\n",
    "\n",
    "cat_preds = cat_model.predict_proba(dataset_test)[:, 1]\n",
    "pd.DataFrame({'Id': dataset_test.index, 'Probability': cat_preds})\\\n",
    "  .to_csv(FOLDER_PATH + 'data/catboost_basic.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f4c83-80e4-496d-90f8-fce2b2a9d26e",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Базовый CatBoost\n",
    "cat_model = CatBoostClassifier(\n",
    "    random_seed=42,\n",
    "    verbose=0,  # Поменял на 0 для RandomizedSearchCV\n",
    "    task_type='CPU',  # 'GPU' если есть\n",
    "    eval_metric='AUC',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Сетка параметров для CatBoost\n",
    "cat_params = {\n",
    "    'iterations': [1000, 1500, 2000],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1, 0.15],\n",
    "    'depth': [4, 5, 6, 7, 8, 9],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'border_count': [32, 64, 128, 256],  # Аналог max_bin\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_data_in_leaf': [1, 3, 5, 7, 10],\n",
    "    'random_strength': [0, 0.5, 1, 2],  # Регуляризация\n",
    "    'bagging_temperature': [0, 0.5, 1],  # Для стохастичности\n",
    "    'fold_len_multiplier': [1.5, 2, 2.5],  # Для overfitting detection\n",
    "}\n",
    "\n",
    "# Кросс-валидация\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomizedSearch для CatBoost\n",
    "cat_search = RandomizedSearchCV(\n",
    "    cat_model,\n",
    "    cat_params,\n",
    "    n_iter=50,  # Можно увеличить до 100 если время есть\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=1,  # CatBoost сам использует потоки\n",
    "    random_state=42,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "print(\"Запускаем поиск параметров для CatBoost...\")\n",
    "print(f\"Будет проверено {50} комбинаций\")\n",
    "\n",
    "cat_search.fit(dataset_train, train_label)\n",
    "\n",
    "print(f\"\\nЛучший CatBoost: {cat_search.best_score_:.6f}\")\n",
    "print(\"Лучшие параметры:\")\n",
    "for param, value in cat_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Обучаем финальную модель с лучшими параметрами\n",
    "print(\"\\nОбучаем финальный CatBoost на всех данных...\")\n",
    "cat_best = CatBoostClassifier(\n",
    "    **cat_search.best_params_,\n",
    "    random_seed=42,\n",
    "    verbose=100,  # Показываем прогресс\n",
    "    task_type='CPU'\n",
    ")\n",
    "\n",
    "cat_best.fit(dataset_train, train_label)\n",
    "\n",
    "# # Создаем сабмит CatBoost\n",
    "# cat_preds = cat_best.predict_proba(dataset_test)[:, 1]\n",
    "# pd.DataFrame({\n",
    "#     'Id': dataset_test.index,\n",
    "#     'Probability': cat_preds\n",
    "# }).to_csv(FOLDER_PATH + 'catboost_tuned.csv', index=False)\n",
    "\n",
    "# print(\"\\n✓ CatBoost с настройкой создан: catboost_tuned.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdc111-9aa6-4c1a-817f-25c9983b6337",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
