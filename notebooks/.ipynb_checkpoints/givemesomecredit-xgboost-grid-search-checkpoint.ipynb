{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-08T19:03:17.506127Z",
     "iopub.status.busy": "2026-02-08T19:03:17.505318Z",
     "iopub.status.idle": "2026-02-08T19:03:17.510759Z",
     "shell.execute_reply": "2026-02-08T19:03:17.509803Z",
     "shell.execute_reply.started": "2026-02-08T19:03:17.506081Z"
    }
   },
   "source": [
    "import os\n",
    "print(\"CPU cores:\", os.cpu_count())\n",
    "# Kaggle дает 4 CPU cores, 16GB RAM, иногда GPU"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T19:03:17.512738Z",
     "iopub.status.busy": "2026-02-08T19:03:17.512035Z",
     "iopub.status.idle": "2026-02-08T19:03:18.079895Z",
     "shell.execute_reply": "2026-02-08T19:03:18.079323Z",
     "shell.execute_reply.started": "2026-02-08T19:03:17.512714Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FOLDER_PATH = '/Users/artemzmailov/Desktop/GiveMeSomeCredit/'\n",
    "dataset_train = pd.read_csv('/kaggle/input/givemesomecredit-datasets/train_full_scaled_pipeline_v1.csv', index_col = 0)\n",
    "dataset_test = pd.read_csv('/kaggle/input/givemesomecredit-datasets/Kaggle_test_full_scaled_pipeline_v1.csv', index_col = 0)\n",
    "train_label = pd.read_csv('/kaggle/input/givemesomecredit-datasets/train_label_pipeline_v1.csv', index_col = 0).squeeze()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T19:07:40.832135Z",
     "iopub.status.busy": "2026-02-08T19:07:40.831282Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. ИНФОРМАЦИЯ О СИСТЕМЕ\n",
    "# ============================================================================\n",
    "\n",
    "import xgboost as xgb\n",
    "print(\"=\" * 60)\n",
    "print(f\"XGBoost версия: {xgb.__version__}\")\n",
    "print(\"Доступен GPU: Tesla P100 16GB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. ПОДГОТОВКА ДАННЫХ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nПОДГОТОВКА ДАННЫХ...\")\n",
    "\n",
    "if isinstance(dataset_train, pd.DataFrame):\n",
    "    X_train = dataset_train.values.astype(np.float32)\n",
    "else:\n",
    "    X_train = dataset_train.astype(np.float32)\n",
    "\n",
    "if isinstance(train_label, pd.Series):\n",
    "    y_train = train_label.values\n",
    "else:\n",
    "    y_train = train_label\n",
    "\n",
    "print(f\"Размер данных: {X_train.shape}\")\n",
    "print(f\"Тип данных: {X_train.dtype}\")\n",
    "\n",
    "# Проверка на NaN/Inf\n",
    "if np.any(np.isnan(X_train)):\n",
    "    print(\"Обнаружены NaN, заменяем на 0...\")\n",
    "    X_train = np.nan_to_num(X_train, nan=0.0)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. НАСТРОЙКА XGBOOST С GPU (ДЛЯ ВЕРСИИ 3.1.0)\n",
    "# ============================================================================\n",
    "\n",
    "# Рассчитываем веса для дисбаланса классов\n",
    "weights_scale = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "print(f\"\\nДисбаланс классов: {weights_scale:.2f}\")\n",
    "\n",
    "# БАЗОВЫЙ КЛАССИФИКАТОР С GPU\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    "    scale_pos_weight=weights_scale,\n",
    "    n_estimators=500,\n",
    "    device='cuda:0',  # ВАЖНО: Для XGBoost 3.1.0 используем 'device', а не tree_method\n",
    "    tree_method='hist',  # Автоматически будет использовать gpu_hist если device='cuda'\n",
    "    n_jobs=1,  # Должно быть 1 при использовании GPU\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=30,\n",
    "    verbosity=0,\n",
    "    enable_categorical=False\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. СЕТКА ПАРАМЕТРОВ ДЛЯ ПОИСКА\n",
    "# ============================================================================\n",
    "\n",
    "xgb_params = {\n",
    "    # Основные параметры\n",
    "    'learning_rate': [0.005, 0.01, 0.015, 0.02, 0.03, 0.05, 0.075, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'min_child_weight': [1, 2, 3, 5, 7, 10],\n",
    "    \n",
    "    # Параметры семплирования\n",
    "    'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95],\n",
    "    'colsample_bylevel': [0.7, 0.75, 0.8, 0.85, 0.9, 1.0],\n",
    "    \n",
    "    # Регуляризация\n",
    "    'reg_alpha': [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1],\n",
    "    'reg_lambda': [0.5, 0.7, 0.9, 1.0, 1.2, 1.5, 2.0, 3.0],\n",
    "    'gamma': [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.5],\n",
    "    \n",
    "    # Параметры устройства (CPU/GPU)\n",
    "    'device': ['cuda:0'],  # Тестируем только GPU\n",
    "    \n",
    "    # Дополнительные параметры\n",
    "    'max_bin': [128, 192, 256, 320],  # Оптимально для гистограммного метода\n",
    "    'grow_policy': ['depthwise', 'lossguide'],\n",
    "    \n",
    "    # Для несбалансированных данных\n",
    "    'scale_pos_weight': [weights_scale * 0.8, weights_scale, weights_scale * 1.2],\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 5. КРОСС-ВАЛИДАЦИЯ\n",
    "# ============================================================================\n",
    "\n",
    "kfold_xgb = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. ЗАПУСК RANDOMIZEDSEARCHCV\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ЗАПУСК ПОИСКА ПАРАМЕТРОВ НА GPU\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Данные: {X_train.shape}\")\n",
    "print(f\"Фолдов: {kfold_xgb.n_splits}\")\n",
    "print(f\"Итераций: 150\")\n",
    "print(f\"Устройство: cuda:0\")\n",
    "\n",
    "rand_search_cv = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=xgb_params,\n",
    "    n_iter=150,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=1,  # ВАЖНО: 1 для GPU\n",
    "    cv=kfold_xgb,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    "    return_train_score=True,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# ЗАПУСКАЕМ ПОИСК\n",
    "print(\"\\nНачинаем обучение на GPU...\")\n",
    "rand_search_cv.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. РЕЗУЛЬТАТЫ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"РЕЗУЛЬТАТЫ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nЛУЧШИЕ ПАРАМЕТРЫ:\")\n",
    "print(\"-\" * 40)\n",
    "for param, value in rand_search_cv.best_params_.items():\n",
    "    print(f\"{param:25}: {value}\")\n",
    "\n",
    "print(f\"\\nЛучший ROC-AUC: {rand_search_cv.best_score_:.6f}\")\n",
    "\n",
    "# Топ-3 комбинации\n",
    "cv_results_df = pd.DataFrame(rand_search_cv.cv_results_)\n",
    "cv_results_df = cv_results_df.sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "print(f\"\\nТОП-3 КОМБИНАЦИИ:\")\n",
    "print(\"-\" * 40)\n",
    "for i in range(min(3, len(cv_results_df))):\n",
    "    row = cv_results_df.iloc[i]\n",
    "    print(f\"{i+1}. Score: {row['mean_test_score']:.6f} ± {row['std_test_score']:.6f}\")\n",
    "    params = row['params']\n",
    "    print(f\"   LR: {params.get('learning_rate', 'N/A')}, \"\n",
    "          f\"Depth: {params.get('max_depth', 'N/A')}, \"\n",
    "          f\"Subsample: {params.get('subsample', 'N/A')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. ФИНАЛЬНАЯ МОДЕЛЬ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"СОЗДАНИЕ ФИНАЛЬНОЙ МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Берем лучшие параметры\n",
    "best_params = rand_search_cv.best_params_.copy()\n",
    "\n",
    "# Создаем финальную модель с увеличенным количеством деревьев\n",
    "final_params = best_params\n",
    "final_params.update({\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 2000,  # Увеличиваем для финальной модели\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbosity': 1,\n",
    "})\n",
    "\n",
    "print(\"\\nПараметры финальной модели:\")\n",
    "for param, value in final_params.items():\n",
    "    if param != 'device':  # Не показываем device в основном выводе\n",
    "        print(f\"  {param}: {value}\")\n",
    "print(f\"  device: cuda:0 (GPU)\")\n",
    "\n",
    "# Создаем и обучаем финальную модель\n",
    "final_model = XGBClassifier(**final_params)\n",
    "\n",
    "print(\"\\nОбучение финальной модели на всех данных...\")\n",
    "final_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "print(\"✓ Финальная модель обучена!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. АНАЛИЗ И СОХРАНЕНИЕ\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"АНАЛИЗ МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Feature importance\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    feature_importance = final_model.feature_importances_\n",
    "    \n",
    "    if hasattr(dataset_train, 'columns'):\n",
    "        feature_names = dataset_train.columns\n",
    "    else:\n",
    "        feature_names = [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nТОП-10 ПРИЗНАКОВ:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, row in importance_df.head(10).iterrows():\n",
    "        print(f\"{str(row['feature'])[:30]:30}: {row['importance']:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Не удалось получить feature importance: {e}\")\n",
    "\n",
    "# Сохранение модели\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"СОХРАНЕНИЕ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Сохраняем параметры\n",
    "with open('best_xgb_params.json', 'w') as f:\n",
    "    json.dump(rand_search_cv.best_params_, f, indent=2)\n",
    "print(\"✓ Параметры сохранены в best_xgb_params.json\")\n",
    "\n",
    "# Сохраняем модель\n",
    "joblib.dump(final_model, 'best_xgb_model.pkl')\n",
    "print(\"✓ Модель сохранена в best_xgb_model.pkl\")\n",
    "\n",
    "# Сохраняем результаты поиска\n",
    "cv_results_df.to_csv('cv_results.csv', index=False)\n",
    "print(\"✓ Результаты поиска сохранены в cv_results.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ГОТОВО!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Лучший скор: {rand_search_cv.best_score_:.6f}\")\n",
    "print(\"Модель готова для предсказаний!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# После завершения поиска сделайте это:\n",
    "\n",
    "# А) Создайте финальную модель с лучшими параметрами\n",
    "best_params = rand_search_cv.best_params_\n",
    "\n",
    "# Увеличьте n_estimators для финальной модели\n",
    "best_params['n_estimators'] = 2000\n",
    "best_params['early_stopping_rounds'] = 100\n",
    "\n",
    "final_model = XGBClassifier(**best_params)\n",
    "\n",
    "# Б) Обучите на всех данных\n",
    "final_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train)],\n",
    "    verbose=100\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T19:49:35.707102Z",
     "iopub.status.busy": "2026-02-08T19:49:35.706472Z",
     "iopub.status.idle": "2026-02-08T19:49:39.241137Z",
     "shell.execute_reply": "2026-02-08T19:49:39.240375Z",
     "shell.execute_reply.started": "2026-02-08T19:49:35.707077Z"
    }
   },
   "source": [
    "# После завершения поиска сделайте это:\n",
    "\n",
    "# А) Создайте финальную модель с лучшими параметрами\n",
    "best_params = rand_search_cv.best_params_\n",
    "\n",
    "# Увеличьте n_estimators для финальной модели\n",
    "best_params['n_estimators'] = 2000\n",
    "best_params['early_stopping_rounds'] = 100\n",
    "\n",
    "final_model = XGBClassifier(**best_params)\n",
    "\n",
    "# Б) Обучите на всех данных\n",
    "final_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_train, y_train)],\n",
    "    verbose=100\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-08T19:50:47.834120Z",
     "iopub.status.idle": "2026-02-08T19:50:47.834379Z",
     "shell.execute_reply": "2026-02-08T19:50:47.834254Z",
     "shell.execute_reply.started": "2026-02-08T19:50:47.834242Z"
    }
   },
   "source": [
    "# 1. Создайте предсказания для тестовых данных\n",
    "# (предполагая, что у вас есть test_data)\n",
    "if 'test_data' in locals():\n",
    "    test_predictions = final_model.predict_proba(dataset_test)[:, 1]\n",
    "    \n",
    "    # Сохраните для сабмита\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': range(len(test_predictions)),\n",
    "        'Probability': test_predictions\n",
    "    })\n",
    "    submission.to_csv('submission_xgb_gpu.csv', index=False)\n",
    "\n",
    "# 2. Проанализируйте важность признаков\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = final_model.feature_importances_\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Feature Importance (XGBoost on GPU)\")\n",
    "plt.bar(range(20), feature_importance[indices][:20])\n",
    "plt.xticks(range(20), [f'Feature {i}' for i in indices[:20]], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9445138,
     "sourceId": 14775996,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
