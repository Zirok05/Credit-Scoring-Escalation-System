# üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (src/)
–ü–∞–ø–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º **Hydra** –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞–º–∏ –∏ **ClearML** –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞
```
src/
‚îú‚îÄ‚îÄ train_lgbm.py # –û–±—É—á–µ–Ω–∏–µ LightGBM
‚îú‚îÄ‚îÄ train_logreg.py # –û–±—É—á–µ–Ω–∏–µ Logistic Regression
‚îú‚îÄ‚îÄ train_xgb.py # –û–±—É—á–µ–Ω–∏–µ XGBoost
‚îú‚îÄ‚îÄ train_rfc.py # –û–±—É—á–µ–Ω–∏–µ Random Forest
‚îú‚îÄ‚îÄ train_catboost.py # –û–±—É—á–µ–Ω–∏–µ CatBoost
‚îú‚îÄ‚îÄ train_dtc.py # –û–±—É—á–µ–Ω–∏–µ Decision Tree
‚îú‚îÄ‚îÄ train_full_dataset.py # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ credit_preprocessor.py # –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (sklearn API)
‚îú‚îÄ‚îÄ data_loader.py # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
‚îî‚îÄ‚îÄ metrics.py # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è ClearML
```

## üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

### –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫ 
```bash
# –ò–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
python src/train_lgbm.py
```

–° –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π:
```
bash
python src/train_lgbm.py experiment.model.use_cv=true
```
–° –¥—Ä—É–≥–∏–º –∫–æ–Ω—Ñ–∏–≥–æ–º:
```
bash
python src/train_lgbm.py --config-name –¥—Ä—É–≥–æ–π_–∫–æ–Ω—Ñ–∏–≥.yaml
```
–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
```
bash
python src/train_lgbm.py model.params.learning_rate=0.1
```

## ‚öôÔ∏è –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

### 1. Hydra –∫–æ–Ω—Ñ–∏–≥–∏
–ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤ `configs/experiment/` (–Ω–∞–ø—Ä–∏–º–µ—Ä, `catboost_experiment.yaml`):
```
yaml
# configs/experiment/catboost_experiment.yaml
defaults:
  - /preprocessor: default   # –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
  - /model: catboost         # –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ CatBoost
  - _self_                   # —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª –º–æ–∂–µ—Ç –∏—Ö –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å

# –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
preprocessor:
  drop_special_codes: true   # –¥–ª—è —ç—Ç–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —É–¥–∞–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∫–æ–¥–∞–º–∏ 96/98

# –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏
model:
  params:
    learning_rate: 0.03      # –º–µ–Ω—è–µ–º learning rate –∏–º–µ–Ω–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
  use_cv: true               # –≤–∫–ª—é—á–∞–µ–º –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
training:
  test_size: 0.2
  random_state: 42
```
### 2. –°–∫—Ä–∏–ø—Ç—ã –æ–±—É—á–µ–Ω–∏—è

#### –ö–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–≤–æ–π —Å–∫—Ä–∏–ø—Ç –≤ src/:  
```
train_lgbm.py  # –æ–±—É—á–µ–Ω–∏–µ LightGBM  
train_logreg.py  # –æ–±—É—á–µ–Ω–∏–µ Logistic Regression  
train_xgb.py  # –æ–±—É—á–µ–Ω–∏–µ XGBoost  
train_rfc.py  # –æ–±—É—á–µ–Ω–∏–µ Random Forest  
train_catboost.py  # –æ–±—É—á–µ–Ω–∏–µ CatBoost  
train_dtc.py  # –æ–±—É—á–µ–Ω–∏–µ Decision Tree  
```
#### –°–∫—Ä–∏–ø—Ç:  
1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥ —á–µ—Ä–µ–∑ Hydra  
2. –°–æ–∑–¥–∞—ë—Ç –¢–∞—Å–∫ –¥–ª—è ClearML  
3. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ data_loader.py  
4. –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å (—Å CV –∏–ª–∏ –±–µ–∑)  
5. –õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ ClearML  
6. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –∏ –º–æ–¥–µ–ª—å  

#### –ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É–µ—Ç:  
**–ú–µ—Ç—Ä–∏–∫–∏**: AUC, AP, Precision, Recall, F1, MCC (Matthews Correlation Coefficient) 
**–ì—Ä–∞—Ñ–∏–∫–∏**: ROC-–∫—Ä–∏–≤–∞—è, PR-–∫—Ä–∏–≤–∞—è, confusion matrix,   
–ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ –∏—Å—Ç–∏–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º  
Feature importance (–¥–ª—è tree-based)  
–ê–Ω–∞–ª–∏–∑ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π  
–†–µ–∑—É–ª—å—Ç–∞—Ç—ã GridSearchCV  

### üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ 29 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:  
GridSearchCV –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤  
–§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (150k —Å—Ç—Ä–æ–∫)  
–ü–æ–¥—Ä–æ–±–Ω–µ–µ: EXPERIMENTS.md  

### üìä –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (train_full_dataset.py)

–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö:  
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ models/best/train_120/  
2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–±–µ–∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ fit)  
3. –û–±—É—á–∞–µ—Ç –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (150k —Å—Ç—Ä–æ–∫)  
4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ models/best/train_150/  
```
bash
python src/train_full_dataset.py
```
### üîß –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏  

1. –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥ –≤ configs/model/ (–ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å lgbm.yaml)  
2. –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –≤ configs/experiment/  
3. –°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è (–ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å train_lgbm.py)  
4. –î–æ–±–∞–≤–∏—Ç—å –º–æ–¥–µ–ª—å –≤ app/utils/data_loader.py –¥–ª—è Streamlit  

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π

| ‚Ññ | –ú–æ–¥–µ–ª—å | AUC | –§–∞–π–ª |
|---|--------|-----|------|
| 1 | üèÜ **LightGBM** | **0.86705** | `lgbm_150_model.pkl` |
| 2 | ü•à XGBoost | 0.86672 | `xgb_150_model.pkl` |
| 3 | ü•â CatBoost | 0.86695 | `catboost_150_model.pkl` |
| 4 | üå≤ Random Forest | 0.86341 | `rfc_150_model.pkl` |
| 5 | üìà Logistic Regression | 0.85804 | `logreg_150_model.pkl` |
| 6 | üå≥ Decision Tree | 0.85330 | `dtc_150_model.pkl` |

*–ü—É—Ç—å –∫–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º: `models/best/train_150/`*  

üìö –ü–æ–¥—Ä–æ–±–Ω–µ–µ  
–ö–æ–Ω—Ñ–∏–≥–∏ Hydra  
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã ClearML  
Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ  
